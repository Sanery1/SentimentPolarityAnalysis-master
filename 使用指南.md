# ğŸ“˜ å¿«é€Ÿä½¿ç”¨æŒ‡å—

> æœ¬é¡¹ç›®æä¾›å‘½ä»¤è¡Œå’Œ Web ç•Œé¢ä¸¤ç§ä½¿ç”¨æ–¹å¼

---

## ğŸŒ Web ç•Œé¢ï¼ˆæ¨èï¼‰

### å¯åŠ¨æ–¹å¼

**Windows ç”¨æˆ·ï¼š**
1. åŒå‡» `å¯åŠ¨WebæœåŠ¡.bat`
2. æˆ–åœ¨ç»ˆç«¯è¿è¡Œï¼š`python app.py`

**Mac/Linux ç”¨æˆ·ï¼š**
```bash
python app.py
```

**è®¿é—®ç•Œé¢ï¼š**
- æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼šhttp://localhost:5000
- åœ¨æ–‡æœ¬æ¡†è¾“å…¥å¥å­ï¼Œç‚¹å‡»ã€Œåˆ†ææƒ…æ„Ÿã€å³å¯

---

## ğŸ’» å‘½ä»¤è¡Œä½¿ç”¨

### æ–¹å¼ 1ï¼šè¿è¡Œæ¼”ç¤ºè„šæœ¬

```bash
python run_demo.py
```

### æ–¹å¼ 2ï¼šåœ¨ä»£ç ä¸­ä½¿ç”¨

#### 2.1 ä½¿ç”¨è¯å…¸åˆ†ç±»å™¨ï¼ˆæ— éœ€è®­ç»ƒï¼‰

```python
from spa.classifiers import DictClassifier

# åˆå§‹åŒ–
classifier = DictClassifier()

# åˆ†æå¥å­
result = classifier.analyse_sentence("å‘³é“å¾ˆå¥½ï¼ŒæœåŠ¡ä¹Ÿä¸é”™")
print("æ­£é¢" if result == 1 else "è´Ÿé¢")  # è¾“å‡ºï¼šæ­£é¢
```

#### 2.2 ä½¿ç”¨æœºå™¨å­¦ä¹ åˆ†ç±»å™¨

```python
from spa.corpus import WaimaiCorpus
from spa.feature_extraction import ChiSquare
from spa.classifiers import BayesClassifier

# 1. åŠ è½½è¯­æ–™
corpus = WaimaiCorpus()
train_data, train_labels = corpus.get_train_corpus(1000)
test_data, test_labels = corpus.get_test_corpus(200)

# 2. ç‰¹å¾é€‰æ‹©
chi_square = ChiSquare(train_data, train_labels)
best_words = chi_square.best_words(2000)

# 3. è®­ç»ƒ
classifier = BayesClassifier(train_data, train_labels, best_words)

# 4. é¢„æµ‹
for data in test_data[:5]:
    result = classifier.classify(data)
    print("æ­£é¢" if result == 1 else "è´Ÿé¢")
```

### æ–¹å¼ 3ï¼šè¿è¡Œå®Œæ•´å®éªŒ

ç¼–è¾‘å¹¶è¿è¡Œ `spa/test.py` ä¸­çš„å®éªŒå‡½æ•°ï¼š

```python
# åœ¨ Python äº¤äº’å¼ç¯å¢ƒæˆ–è„šæœ¬ä¸­
from spa.test import test_dict

# è¿è¡Œè¯å…¸åˆ†ç±»å™¨å®éªŒ
test_dict()
```

æˆ–è€…å–æ¶ˆ `test.py` åº•éƒ¨çš„æ³¨é‡Šæ¥è¿è¡Œå…¶ä»–å®éªŒï¼š
```python
# test_waimai()   # å¤–å–æ•°æ®é›†
# test_hotel()    # é…’åº—æ•°æ®é›†
# test_movie2()   # ç”µå½±æ•°æ®é›†
```

---

## ğŸ“Š å¯ç”¨çš„æ•°æ®é›†

- **WaimaiCorpus**ï¼šä¸­æ–‡å¤–å–è¯„è®ºï¼ˆ4000ä¸ªæ­£é¢ + 4000ä¸ªè´Ÿé¢ï¼‰
- **Waimai2Corpus**ï¼šä¸­æ–‡å¤–å–è¯„è®ºï¼ˆå¦ä¸€ç‰ˆæœ¬ï¼‰
- **HotelCorpus**ï¼šä¸­æ–‡é…’åº—è¯„è®º
- **MovieCorpus**ï¼šè‹±æ–‡ç”µå½±è¯„è®º
- **Movie2Corpus**ï¼šè‹±æ–‡ç”µå½±è¯„è®ºï¼ˆå¦ä¸€ç‰ˆæœ¬ï¼‰

---

## ğŸ”§ æ”¯æŒçš„åˆ†ç±»å™¨

| åˆ†ç±»å™¨ | ç±»å | ç‰¹ç‚¹ | éœ€è¦è®­ç»ƒ |
|--------|------|------|---------|
| è¯å…¸è§„åˆ™ | `DictClassifier` | åŸºäºæƒ…æ„Ÿè¯å…¸å’Œè§„åˆ™ï¼Œæ”¯æŒä¸­æ–‡ | âŒ |
| æœ´ç´ è´å¶æ–¯ | `BayesClassifier` | å¿«é€Ÿã€ç®€å•ã€æ•ˆæœå¥½ | âœ… |
| Kè¿‘é‚» | `KNNClassifier` | å¯è®¾ç½® K å€¼ | âœ… |
| æœ€å¤§ç†µ | `MaxEntClassifier` | GIS ç®—æ³•ï¼ˆè¾ƒæ…¢ï¼‰ | âœ… |
| æ”¯æŒå‘é‡æœº | `SVMClassifier` | åŸºäº sklearnï¼Œæ•ˆæœé€šå¸¸æœ€å¥½ | âœ… |

---

## ğŸ“ ç¤ºä¾‹ä»£ç ç‰‡æ®µ

### æµ‹è¯•ä¸åŒçš„å¥å­

```python
from spa.classifiers import DictClassifier

classifier = DictClassifier()

sentences = [
    "å‘³é“å¾ˆå¥½ï¼ŒæœåŠ¡ä¹Ÿä¸é”™",
    "å¤ªéš¾åƒäº†ï¼Œå†ä¹Ÿä¸æ¥äº†",
    "è¦æ˜¯ç±³é¥­å†å¤šç‚¹å„¿å°±å¥½äº†",
    "ç¯å¢ƒä¸€èˆ¬ï¼Œä»·æ ¼æœ‰ç‚¹è´µ",
    "éå¸¸æ»¡æ„ï¼Œä¸‹æ¬¡è¿˜ä¼šå†æ¥"
]

for sent in sentences:
    result = classifier.analyse_sentence(sent)
    print(f"{sent} => {'æ­£é¢' if result == 1 else 'è´Ÿé¢'}")
```

### æ¯”è¾ƒå¤šä¸ªåˆ†ç±»å™¨

```python
from spa.corpus import WaimaiCorpus
from spa.feature_extraction import ChiSquare
from spa.classifiers import BayesClassifier, KNNClassifier, SVMClassifier

# å‡†å¤‡æ•°æ®
corpus = WaimaiCorpus()
train_data, train_labels = corpus.get_train_corpus(500)
test_data, test_labels = corpus.get_test_corpus(100)

# ç‰¹å¾é€‰æ‹©
chi = ChiSquare(train_data, train_labels)
best_words = chi.best_words(1000)

# è®­ç»ƒå¤šä¸ªåˆ†ç±»å™¨
classifiers = {
    "è´å¶æ–¯": BayesClassifier(train_data, train_labels, best_words),
    "KNN": KNNClassifier(train_data, train_labels, k=5, best_words=best_words),
    "SVM": SVMClassifier(train_data, train_labels, best_words, C=10)
}

# è¯„ä¼°
for name, clf in classifiers.items():
    results = [clf.classify(data) for data in test_data]
    acc = sum([1 for i in range(len(test_labels)) 
               if test_labels[i] == results[i]]) / len(test_labels)
    print(f"{name} å‡†ç¡®ç‡: {acc*100:.2f}%")
```

### ä¿å­˜å’ŒåŠ è½½ç»“æœ

```python
from spa.tools import Write2File, get_accuracy

# è¯„ä¼°å¹¶ä¿å­˜
origin_labels = test_labels
classify_labels = [classifier.classify(data) for data in test_data]

results = get_accuracy(origin_labels, classify_labels, 
                      [len(train_data), len(test_data), len(best_words)])

Write2File.write_contents("spa/f_runout/my_results.xls", results)
print("ç»“æœå·²ä¿å­˜åˆ° spa/f_runout/my_results.xls")
```

---

## âš™ï¸ è¶…å‚æ•°è°ƒä¼˜å»ºè®®

### æœ´ç´ è´å¶æ–¯
- `feature_num`: 2000-5000ï¼ˆç‰¹å¾è¯æ•°é‡ï¼‰

### KNN
- `k`: 3, 5, 7, 9, 11, 13ï¼ˆå¥‡æ•°é¿å…å¹³å±€ï¼‰
- `feature_num`: 3000-5000

### SVM
- `C`: 10, 50, 100, 150ï¼ˆæ­£åˆ™åŒ–å‚æ•°ï¼‰
- `feature_num`: 3000-5000

### æœ€å¤§ç†µ
- `max_iter`: 100-500ï¼ˆè¿­ä»£æ¬¡æ•°ï¼‰
- `feature_num`: 2000-4000

---

## ğŸ› å¸¸è§é—®é¢˜

### Q: å¦‚ä½•æŸ¥çœ‹è¯¦ç»†çš„åˆ†ç±»è¿‡ç¨‹ï¼Ÿ
A: ä½¿ç”¨ `DictClassifier` çš„ `print_show` å‚æ•°ï¼š
```python
classifier.analyse_sentence("å¾ˆå¥½åƒ", print_show=True)
```

### Q: å¦‚ä½•ä¿å­˜å®éªŒç»“æœï¼Ÿ
A: å®éªŒç»“æœä¼šè‡ªåŠ¨ä¿å­˜åˆ° `spa/f_runout/` ç›®å½•ï¼Œæ–‡ä»¶ååŒ…å«æ—¶é—´æˆ³ã€‚

### Q: å¦‚ä½•æ·»åŠ è‡ªå·±çš„è¯å…¸ï¼Ÿ
A: ç¼–è¾‘ `spa/f_dict/` ä¸‹çš„ç›¸åº”æ–‡ä»¶ï¼Œæ ¼å¼ä¸ºï¼š`è¯è¯­ æƒé‡`

### Q: å¦‚ä½•ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ï¼Ÿ
A: å‚è€ƒ `spa/corpus.py` ä¸­çš„ `Corpus` ç±»ï¼Œåˆ›å»ºä½ è‡ªå·±çš„è¯­æ–™ç±»ã€‚

---

## ğŸ“š æ›´å¤šä¿¡æ¯

- å®Œæ•´æ–‡æ¡£ï¼šå‚è§ `README_NEW.md`
- åŸå§‹æ–‡æ¡£ï¼šå‚è§ `README.md`
- æºä»£ç ï¼šæŸ¥çœ‹ `spa/` ç›®å½•ä¸‹çš„å„ä¸ª Python æ–‡ä»¶

---

## âœ¨ é¡¹ç›®äº®ç‚¹

1. **å¤šç§ç®—æ³•**ï¼šæ”¯æŒ 5 ç§ä¸åŒçš„åˆ†ç±»æ–¹æ³•
2. **ä¸­è‹±æ–‡æ”¯æŒ**ï¼šå†…ç½®å¤šä¸ªä¸­è‹±æ–‡æ•°æ®é›†
3. **å¼€ç®±å³ç”¨**ï¼šè¯å…¸åˆ†ç±»å™¨æ— éœ€è®­ç»ƒå³å¯ä½¿ç”¨
4. **å®Œæ•´æµç¨‹**ï¼šä»æ•°æ®åŠ è½½åˆ°è¯„ä¼°çš„å®Œæ•´å®ç°
5. **å¯æ‰©å±•**ï¼šæ˜“äºæ·»åŠ æ–°çš„è¯å…¸ã€æ•°æ®é›†å’Œåˆ†ç±»å™¨

---

**ç¥ä½¿ç”¨æ„‰å¿«ï¼å¦‚æœ‰é—®é¢˜è¯·æŸ¥é˜…æ–‡æ¡£æˆ–æ£€æŸ¥ `spa/test.py` ä¸­çš„ç¤ºä¾‹ä»£ç ã€‚**
