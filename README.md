# ğŸ­ æƒ…æ„Ÿææ€§åˆ†æç³»ç»Ÿ

[![Python Version](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/flask-2.0+-green.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/license-MIT-orange.svg)](LICENSE)

åŸºäºæƒ…æ„Ÿè¯å…¸å’Œæœºå™¨å­¦ä¹ çš„ä¸­è‹±æ–‡æ–‡æœ¬æƒ…æ„Ÿåˆ†æç³»ç»Ÿï¼Œæ”¯æŒå‘½ä»¤è¡Œå’Œ Web ç•Œé¢ä¸¤ç§ä½¿ç”¨æ–¹å¼ã€‚

## ğŸ“‹ ç›®å½•

- [åŠŸèƒ½ç‰¹ç‚¹](#åŠŸèƒ½ç‰¹ç‚¹)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [å®‰è£…éƒ¨ç½²](#å®‰è£…éƒ¨ç½²)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [æŠ€æœ¯è¯´æ˜](#æŠ€æœ¯è¯´æ˜)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

## âœ¨ åŠŸèƒ½ç‰¹ç‚¹

### æ ¸å¿ƒåŠŸèƒ½
- ğŸ¯ **å¤šç®—æ³•æ”¯æŒ**ï¼šè¯å…¸è§„åˆ™ã€æœ´ç´ è´å¶æ–¯ã€KNNã€SVMã€æœ€å¤§ç†µ
- ğŸŒ **åŒè¯­æ”¯æŒ**ï¼šä¸­æ–‡å’Œè‹±æ–‡æƒ…æ„Ÿåˆ†æ
- ğŸ’» **Web ç•Œé¢**ï¼šç¾è§‚çš„äº¤äº’å¼ç½‘é¡µï¼Œæ”¯æŒå•å¥å’Œæ‰¹é‡åˆ†æ
- ğŸ“Š **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒæ‰¹é‡æ–‡æœ¬åˆ†æå’Œç»“æœå¯¼å‡º
- ğŸ“ˆ **å®Œæ•´è¯„ä¼°**ï¼šPrecisionã€Recallã€F1-score ç­‰æŒ‡æ ‡

### æŠ€æœ¯ç‰¹è‰²
- ğŸ” **å¡æ–¹ç‰¹å¾é€‰æ‹©**ï¼šæ™ºèƒ½ç­›é€‰æœ€æœ‰æ•ˆçš„ç‰¹å¾è¯
- ğŸ“ **ä¸­æ–‡åˆ†è¯**ï¼šåŸºäº jieba çš„é«˜æ€§èƒ½åˆ†è¯
- ğŸ¨ **å¯è§†åŒ–ç»“æœ**ï¼šå½©è‰²ç•Œé¢å±•ç¤ºåˆ†æç»“æœ
- ğŸš€ **é«˜æ€§èƒ½**ï¼šåˆ†ç±»å™¨å•ä¾‹æ¨¡å¼ï¼Œå“åº”é€Ÿåº¦å¿«
- ğŸ“± **å“åº”å¼è®¾è®¡**ï¼šè‡ªé€‚åº” PCã€å¹³æ¿ã€æ‰‹æœºå±å¹•

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•ä¸€ï¼šWeb ç•Œé¢ï¼ˆæ¨èï¼‰â­

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. å¯åŠ¨æœåŠ¡å™¨
python app.py

# 3. åœ¨æµè§ˆå™¨æ‰“å¼€
# http://localhost:5000
```

**Windows ç”¨æˆ·**å¯ä»¥ç›´æ¥åŒå‡» `å¯åŠ¨WebæœåŠ¡.bat` ä¸€é”®å¯åŠ¨ï¼

### æ–¹æ³•äºŒï¼šå‘½ä»¤è¡Œä½¿ç”¨

```python
from spa.classifiers import DictClassifier

# åˆå§‹åŒ–åˆ†ç±»å™¨
classifier = DictClassifier()

# åˆ†ææ–‡æœ¬
result = classifier.analyse_sentence("å‘³é“å¾ˆå¥½ï¼ŒæœåŠ¡ä¹Ÿä¸é”™")
print("æ­£é¢" if result == 1 else "è´Ÿé¢")  # è¾“å‡ºï¼šæ­£é¢
```

## ğŸ’» ç³»ç»Ÿè¦æ±‚

### æœ€ä½é…ç½®
- **æ“ä½œç³»ç»Ÿ**ï¼šWindows 10+ / macOS 10.14+ / Linux
- **Python**ï¼š3.7 æˆ–æ›´é«˜ç‰ˆæœ¬
- **å†…å­˜**ï¼šè‡³å°‘ 2GB RAM
- **å­˜å‚¨**ï¼šè‡³å°‘ 500MB å¯ç”¨ç©ºé—´

### æ¨èé…ç½®
- **Python**ï¼š3.8 - 3.10
- **å†…å­˜**ï¼š4GB+ RAM
- **å¤„ç†å™¨**ï¼šå¤šæ ¸ CPUï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰

## ğŸ“¦ å®‰è£…éƒ¨ç½²

### 1. å®‰è£… Python ä¾èµ–

```bash
pip install -r requirements.txt
```

ä¾èµ–åŒ…åˆ—è¡¨ï¼š
- `numpy>=1.19.0` - æ•°å€¼è®¡ç®—
- `scikit-learn>=0.24.0` - æœºå™¨å­¦ä¹ ç®—æ³•
- `jieba>=0.42.0` - ä¸­æ–‡åˆ†è¯
- `xlwt>=1.3.0` - Excel è¾“å‡º
- `flask>=2.0.0` - Web æ¡†æ¶
- `flask-cors>=3.0.0` - è·¨åŸŸæ”¯æŒ

### 2. éªŒè¯å®‰è£…

```bash
# æµ‹è¯•å‘½ä»¤è¡Œç‰ˆæœ¬
python run_demo.py

# æµ‹è¯• Web ç‰ˆæœ¬
python app.py
# ç„¶åè®¿é—® http://localhost:5000
```

### 3. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆå¯é€‰ï¼‰

ä½¿ç”¨ Gunicorn éƒ¨ç½²ï¼š

```bash
# å®‰è£… Gunicorn
pip install gunicorn

# å¯åŠ¨æœåŠ¡ï¼ˆ4ä¸ªå·¥ä½œè¿›ç¨‹ï¼‰
gunicorn -w 4 -b 0.0.0.0:5000 app:app
```

ä½¿ç”¨ Nginx åå‘ä»£ç†ï¼š

```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://127.0.0.1:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### Web ç•Œé¢ä½¿ç”¨

1. **å¯åŠ¨æœåŠ¡å™¨**
   ```bash
   python app.py
   ```

2. **è®¿é—®ç•Œé¢**
   - åœ¨æµè§ˆå™¨æ‰“å¼€ http://localhost:5000
   - ä½ ä¼šçœ‹åˆ°ä¸€ä¸ªæ¼‚äº®çš„ç´«è‰²æ¸å˜ç•Œé¢

3. **å•å¥åˆ†æ**
   - åœ¨æ–‡æœ¬æ¡†è¾“å…¥è¦åˆ†æçš„å¥å­
   - ç‚¹å‡»ã€ŒğŸ” åˆ†ææƒ…æ„Ÿã€æŒ‰é’®
   - æŸ¥çœ‹ç»“æœï¼ˆæ­£é¢/è´Ÿé¢ï¼‰

4. **æ‰¹é‡åˆ†æ**
   - åœ¨æ‰¹é‡åˆ†æåŒºåŸŸè¾“å…¥å¤šä¸ªå¥å­
   - ç‚¹å‡»ã€Œâ• æ·»åŠ ã€æ·»åŠ åˆ°åˆ—è¡¨
   - ç‚¹å‡»ã€ŒğŸš€ æ‰¹é‡åˆ†æã€ä¸€æ¬¡æ€§åˆ†ææ‰€æœ‰æ–‡æœ¬

5. **å¿«é€Ÿç¤ºä¾‹**
   - ç‚¹å‡»é¡µé¢ä¸Šçš„ç¤ºä¾‹æŒ‰é’®å¿«é€Ÿä½“éªŒ

### API è°ƒç”¨

#### å•å¥åˆ†æ

```python
import requests

url = "http://localhost:5000/api/analyze"
data = {"text": "å‘³é“å¾ˆå¥½ï¼ŒæœåŠ¡ä¹Ÿä¸é”™"}
response = requests.post(url, json=data)
result = response.json()

print(result['label'])  # è¾“å‡ºï¼šæ­£é¢ ğŸ˜Š
```

#### æ‰¹é‡åˆ†æ

```python
import requests

url = "http://localhost:5000/api/batch_analyze"
data = {
    "texts": [
        "å‘³é“å¾ˆå¥½ï¼ŒæœåŠ¡ä¹Ÿä¸é”™",
        "å¤ªéš¾åƒäº†ï¼Œå†ä¹Ÿä¸æ¥äº†",
        "ä¸€èˆ¬èˆ¬ï¼Œæ²¡ä»€ä¹ˆç‰¹è‰²"
    ]
}
response = requests.post(url, json=data)
results = response.json()

for item in results['results']:
    print(f"{item['text']} => {item['label']}")
```

### å‘½ä»¤è¡Œä½¿ç”¨

#### åŸºäºè¯å…¸çš„åˆ†ç±»å™¨

```python
from spa.classifiers import DictClassifier

# åˆå§‹åŒ–
classifier = DictClassifier()

# å•å¥åˆ†æ
result = classifier.analyse_sentence("å‘³é“å¾ˆå¥½ï¼ŒæœåŠ¡ä¹Ÿä¸é”™")
print("æ­£é¢" if result == 1 else "è´Ÿé¢")

# åˆ†ææ–‡ä»¶
results = classifier.analysis_file(
    filepath_in="input.txt",
    filepath_out="output.txt",
    encoding="utf-8"
)
```

#### æœºå™¨å­¦ä¹ åˆ†ç±»å™¨

```python
from spa.corpus import WaimaiCorpus
from spa.feature_extraction import ChiSquare
from spa.classifiers import BayesClassifier, KNNClassifier, SVMClassifier

# 1. åŠ è½½è¯­æ–™
corpus = WaimaiCorpus()
train_data, train_labels = corpus.get_train_corpus(1000)
test_data, test_labels = corpus.get_test_corpus(200)

# 2. ç‰¹å¾é€‰æ‹©
chi_square = ChiSquare(train_data, train_labels)
best_words = chi_square.best_words(2000)

# 3. è®­ç»ƒåˆ†ç±»å™¨
# æœ´ç´ è´å¶æ–¯
classifier = BayesClassifier(train_data, train_labels, best_words)

# æˆ– KNN
# classifier = KNNClassifier(train_data, train_labels, k=13, best_words=best_words)

# æˆ– SVM
# classifier = SVMClassifier(train_data, train_labels, best_words, C=150)

# 4. é¢„æµ‹
for data in test_data[:5]:
    result = classifier.classify(data)
    print("æ­£é¢" if result == 1 else "è´Ÿé¢")
```

#### è¿è¡Œå®Œæ•´å®éªŒ

```python
# ç¼–è¾‘ spa/test.py ä¸­çš„å‡½æ•°
from spa.test import test_waimai, test_hotel, test_dict

# è¿è¡Œä¸åŒæ•°æ®é›†çš„å®éªŒ
test_waimai()   # å¤–å–æ•°æ®é›†
test_hotel()    # é…’åº—æ•°æ®é›†
test_dict()     # è¯å…¸æ–¹æ³•
```

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
SentimentPolarityAnalysis/
â”œâ”€â”€ app.py                      # Flask Web æœåŠ¡å™¨
â”œâ”€â”€ run_demo.py                 # å‘½ä»¤è¡Œæ¼”ç¤ºè„šæœ¬
â”œâ”€â”€ requirements.txt            # Python ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ README.md                   # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ ä½¿ç”¨æŒ‡å—.md                  # è¯¦ç»†ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ å¯åŠ¨WebæœåŠ¡.bat              # Windows å¯åŠ¨è„šæœ¬
â”‚
â”œâ”€â”€ templates/                  # Web æ¨¡æ¿
â”‚   â””â”€â”€ index.html             # å‰ç«¯é¡µé¢
â”‚
â”œâ”€â”€ spa/                        # æ ¸å¿ƒä»£ç åŒ…
â”‚   â”œâ”€â”€ __init__.py            # åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ classifiers.py         # åˆ†ç±»å™¨å®ç°
â”‚   â”‚   â”œâ”€â”€ DictClassifier     # åŸºäºè¯å…¸
â”‚   â”‚   â”œâ”€â”€ BayesClassifier    # æœ´ç´ è´å¶æ–¯
â”‚   â”‚   â”œâ”€â”€ KNNClassifier      # Kè¿‘é‚»
â”‚   â”‚   â”œâ”€â”€ MaxEntClassifier   # æœ€å¤§ç†µ
â”‚   â”‚   â””â”€â”€ SVMClassifier      # æ”¯æŒå‘é‡æœº
â”‚   â”‚
â”‚   â”œâ”€â”€ corpus.py              # è¯­æ–™åŠ è½½
â”‚   â”‚   â”œâ”€â”€ WaimaiCorpus       # å¤–å–è¯„è®º
â”‚   â”‚   â”œâ”€â”€ HotelCorpus        # é…’åº—è¯„è®º
â”‚   â”‚   â”œâ”€â”€ MovieCorpus        # ç”µå½±è¯„è®ºï¼ˆè‹±æ–‡ï¼‰
â”‚   â”‚   â””â”€â”€ Movie2Corpus       # ç”µå½±è¯„è®ºv2
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_extraction.py # ç‰¹å¾é€‰æ‹©
â”‚   â”‚   â””â”€â”€ ChiSquare          # å¡æ–¹æ£€éªŒ
â”‚   â”‚
â”‚   â”œâ”€â”€ tools.py               # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ get_accuracy       # è®¡ç®—å‡†ç¡®ç‡
â”‚   â”‚   â””â”€â”€ Write2File         # æ–‡ä»¶è¾“å‡º
â”‚   â”‚
â”‚   â”œâ”€â”€ test.py                # å®éªŒè„šæœ¬
â”‚   â”‚
â”‚   â”œâ”€â”€ f_corpus/              # è®­ç»ƒ/æµ‹è¯•è¯­æ–™
â”‚   â”‚   â”œâ”€â”€ ch_hotel_corpus.txt
â”‚   â”‚   â”œâ”€â”€ ch_waimai_corpus.txt
â”‚   â”‚   â”œâ”€â”€ ch_waimai2_corpus.txt
â”‚   â”‚   â”œâ”€â”€ en_movie_corpus.txt
â”‚   â”‚   â””â”€â”€ en_movie2_corpus.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ f_dict/                # æƒ…æ„Ÿè¯å…¸èµ„æº
â”‚   â”‚   â”œâ”€â”€ positive_dict.txt  # æ­£å‘è¯å…¸
â”‚   â”‚   â”œâ”€â”€ negative_dict.txt  # è´Ÿå‘è¯å…¸
â”‚   â”‚   â”œâ”€â”€ adverb_dict.txt    # å‰¯è¯è¯å…¸
â”‚   â”‚   â”œâ”€â”€ denial_dict.txt    # å¦å®šè¯è¯å…¸
â”‚   â”‚   â”œâ”€â”€ conjunction_dict.txt  # è¿è¯è¯å…¸
â”‚   â”‚   â”œâ”€â”€ punctuation_dict.txt  # æ ‡ç‚¹è¯å…¸
â”‚   â”‚   â”œâ”€â”€ phrase_dict.txt    # çŸ­è¯­è¯å…¸
â”‚   â”‚   â””â”€â”€ user.dict          # ç”¨æˆ·è¯å…¸
â”‚   â”‚
â”‚   â””â”€â”€ f_runout/              # å®éªŒç»“æœè¾“å‡º
â”‚
â””â”€â”€ files/                      # å…¶ä»–èµ„æºæ–‡ä»¶
    â””â”€â”€ pic/                   # å›¾ç‰‡èµ„æº
```

## ğŸ”¬ æŠ€æœ¯è¯´æ˜

### æ”¯æŒçš„åˆ†ç±»å™¨

| åˆ†ç±»å™¨ | ç±»å | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|--------|------|------|----------|
| è¯å…¸è§„åˆ™ | `DictClassifier` | æ— éœ€è®­ç»ƒï¼ŒåŸºäºè§„åˆ™ | ä¸­æ–‡æƒ…æ„Ÿåˆ†æï¼Œå¿«é€Ÿéƒ¨ç½² |
| æœ´ç´ è´å¶æ–¯ | `BayesClassifier` | å¿«é€Ÿã€ç®€å•ã€æ•ˆæœå¥½ | æ–‡æœ¬åˆ†ç±»åŸºçº¿ |
| Kè¿‘é‚» | `KNNClassifier` | ç›´è§‚ã€æ˜“ç†è§£ | å°è§„æ¨¡æ•°æ®é›† |
| æœ€å¤§ç†µ | `MaxEntClassifier` | ç†è®ºå®Œå–„ | ç ”ç©¶å’Œå­¦ä¹  |
| æ”¯æŒå‘é‡æœº | `SVMClassifier` | æ•ˆæœé€šå¸¸æœ€å¥½ | ç”Ÿäº§ç¯å¢ƒ |

### è¯å…¸è§„åˆ™æ–¹æ³•ï¼ˆDictClassifierï¼‰

**æ ¸å¿ƒæœºåˆ¶ï¼š**
1. **æƒ…æ„Ÿè¯å…¸**ï¼šåŒ…å«æ­£å‘è¯å’Œè´Ÿå‘è¯ï¼Œæ¯ä¸ªè¯å¸¦æƒé‡
2. **å‰¯è¯ä¿®æ­£**ï¼šç¨‹åº¦å‰¯è¯å¢å¼ºæƒ…æ„Ÿå¼ºåº¦ï¼ˆå¦‚"å¾ˆ"ã€"éå¸¸"ï¼‰
3. **å¦å®šè¯å¤„ç†**ï¼šå¦å®šè¯åè½¬æƒ…æ„Ÿææ€§ï¼ˆå¦‚"ä¸"ã€"æ²¡æœ‰"ï¼‰
4. **å±€éƒ¨çª—å£**ï¼šæ£€æŸ¥æƒ…æ„Ÿè¯å‰3ä¸ªè¯çš„ä¿®é¥°ä½œç”¨
5. **å¥å¼è¯†åˆ«**ï¼šè¯†åˆ«ç‰¹æ®Šå¥å¼ï¼ˆå¦‚"å¦‚æœ...å°±å¥½äº†"ï¼‰
6. **å­å¥åˆ†æ**ï¼šæŒ‰æ ‡ç‚¹æ‹†åˆ†å¥å­ï¼Œé€ä¸ªåˆ†æ

**ä¼˜ç‚¹ï¼š**
- âœ… æ— éœ€è®­ç»ƒæ•°æ®
- âœ… å¯è§£é‡Šæ€§å¼º
- âœ… é€‚åˆä¸­æ–‡åˆ†æ
- âœ… å¿«é€Ÿéƒ¨ç½²

**å±€é™ï¼š**
- âŒ è¯å…¸ç»´æŠ¤æˆæœ¬é«˜
- âŒ éš¾ä»¥å¤„ç†å¤æ‚è¯­å¢ƒ
- âŒ å‡†ç¡®ç‡ä¾èµ–è¯å…¸è´¨é‡

### æœºå™¨å­¦ä¹ æ–¹æ³•

**ç‰¹å¾å·¥ç¨‹ï¼š**
- **å¡æ–¹æ£€éªŒï¼ˆChi-Squareï¼‰**ï¼šé€‰æ‹©ä¸åˆ†ç±»æœ€ç›¸å…³çš„ top-N ç‰¹å¾è¯
- **è¯é¢‘å‘é‡åŒ–**ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºåŸºäºç‰¹å¾è¯çš„æ•°å€¼å‘é‡

**åˆ†ç±»ç®—æ³•ï¼š**
- **æœ´ç´ è´å¶æ–¯**ï¼šåŸºäºè¯é¢‘æ¦‚ç‡ï¼Œä½¿ç”¨ log æ¦‚ç‡é¿å…ä¸‹æº¢
- **KNN**ï¼šåŸºäºæ¬§æ°è·ç¦»ï¼Œæ”¯æŒå•ä¸ªæˆ–å¤šä¸ª K å€¼
- **SVM**ï¼šä½¿ç”¨ sklearn.svm.SVCï¼Œæ”¯æŒå‚æ•° C è°ƒä¼˜
- **æœ€å¤§ç†µ**ï¼šGIS ç®—æ³•å®ç°ï¼ˆçº¯ Pythonï¼Œè¾ƒæ…¢ï¼‰

### æ•°æ®é›†

| æ•°æ®é›† | è¯­è¨€ | ç±»åˆ« | è§„æ¨¡ | è¯´æ˜ |
|--------|------|------|------|------|
| å¤–å–è¯„è®º | ä¸­æ–‡ | æ­£/è´Ÿ | 8000æ¡ | WaimaiCorpus |
| é…’åº—è¯„è®º | ä¸­æ–‡ | æ­£/è´Ÿ | 6000æ¡ | HotelCorpus |
| ç”µå½±è¯„è®º | è‹±æ–‡ | æ­£/è´Ÿ | 2000æ¡ | MovieCorpus |

**è¯­æ–™æ ¼å¼ï¼š**
```
pos	å‘³é“	å¾ˆ	å¥½	æœåŠ¡	ä¹Ÿ	ä¸é”™
neg	å¤ª	éš¾åƒ	äº†	å†ä¹Ÿ	ä¸	æ¥	äº†
```

æ¯è¡Œä»¥ `pos`ï¼ˆæ­£é¢ï¼‰æˆ– `neg`ï¼ˆè´Ÿé¢ï¼‰å¼€å¤´ï¼Œåæ¥åˆ†è¯åçš„ tokenã€‚

### è¯„ä¼°æŒ‡æ ‡

```python
from spa.tools import get_accuracy

results = get_accuracy(
    origin_labels=test_labels,
    classify_labels=predictions,
    parameters=[train_num, test_num, feature_num]
)
```

**è¾“å‡ºæŒ‡æ ‡ï¼š**
- **Precisionï¼ˆç²¾ç¡®ç‡ï¼‰**ï¼šé¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬ä¸­å®é™…ä¸ºæ­£çš„æ¯”ä¾‹
- **Recallï¼ˆå¬å›ç‡ï¼‰**ï¼šå®é™…ä¸ºæ­£çš„æ ·æœ¬ä¸­è¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹
- **F1-score**ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
- **æ€»ä½“å‡†ç¡®ç‡**ï¼šæ­£ç¡®é¢„æµ‹çš„æ ·æœ¬å æ€»æ ·æœ¬çš„æ¯”ä¾‹

## ğŸ› å¸¸è§é—®é¢˜

### Q1: å¯åŠ¨æ—¶æŠ¥é”™ "ModuleNotFoundError: No module named 'flask'"

**è§£å†³æ–¹æ³•ï¼š**
```bash
pip install flask flask-cors
```

### Q2: é¡µé¢æ˜¾ç¤ºç©ºç™½æˆ–æ— æ³•è®¿é—®

**æ£€æŸ¥æ¸…å•ï¼š**
1. ç¡®è®¤æœåŠ¡å™¨å·²å¯åŠ¨ï¼ˆç»ˆç«¯æœ‰è¾“å‡ºï¼‰
2. æ£€æŸ¥è®¿é—®åœ°å€æ˜¯å¦æ­£ç¡®ï¼ˆhttp://localhost:5000ï¼‰
3. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
4. å°è¯•ä½¿ç”¨ http://127.0.0.1:5000

### Q3: ä¸­æ–‡æ˜¾ç¤ºä¹±ç 

**è§£å†³æ–¹æ³•ï¼š**
- ç¡®ä¿æ‰€æœ‰æ–‡ä»¶ä½¿ç”¨ UTF-8 ç¼–ç 
- Windows ç”¨æˆ·åœ¨ç»ˆç«¯è¿è¡Œï¼š`chcp 65001`

### Q4: è¯å…¸åˆ†ç±»å™¨æ‰¾ä¸åˆ°è¯å…¸æ–‡ä»¶

**åŸå› ï¼š** è·¯å¾„é—®é¢˜ï¼ˆå·²ä¿®å¤ï¼‰

**éªŒè¯ï¼š**
```python
from spa.classifiers import DictClassifier
classifier = DictClassifier()  # åº”è¯¥èƒ½æ­£å¸¸åˆå§‹åŒ–
```

### Q5: åˆ†æé€Ÿåº¦å¾ˆæ…¢

**ä¼˜åŒ–å»ºè®®ï¼š**
1. **é¦–æ¬¡åŠ è½½æ…¢**ï¼šåˆ†ç±»å™¨åˆå§‹åŒ–éœ€è¦æ—¶é—´ï¼Œåç»­ä¼šå¿«å¾ˆå¤š
2. **ä½¿ç”¨ç¼“å­˜**ï¼šä¿æŒæœåŠ¡å™¨è¿è¡Œï¼Œåˆ©ç”¨å•ä¾‹æ¨¡å¼
3. **å‡å°‘ç‰¹å¾æ•°**ï¼šç‰¹å¾é€‰æ‹©æ—¶ä½¿ç”¨è¾ƒå°‘çš„ç‰¹å¾è¯ï¼ˆå¦‚ 2000-3000ï¼‰
4. **ä½¿ç”¨æ›´å¿«çš„ç®—æ³•**ï¼šæœ´ç´ è´å¶æ–¯ > SVM > KNN

### Q6: å¦‚ä½•åœ¨å±€åŸŸç½‘å†…è®¿é—®

**æ–¹æ³•ï¼š**
1. ç¡®ä¿æœåŠ¡å™¨ç»‘å®šåˆ° `0.0.0.0`ï¼ˆå·²é»˜è®¤ï¼‰
2. æŸ¥çœ‹æœ¬æœº IP åœ°å€ï¼š
   - Windows: `ipconfig`
   - Mac/Linux: `ifconfig` æˆ– `ip addr`
3. åœ¨å…¶ä»–è®¾å¤‡è®¿é—®ï¼š`http://<ä½ çš„IP>:5000`

### Q7: å¦‚ä½•æ·»åŠ è‡ªå·±çš„è¯å…¸

**æ­¥éª¤ï¼š**
1. ç¼–è¾‘ `spa/f_dict/` ä¸‹çš„ç›¸åº”æ–‡ä»¶
2. æ ¼å¼ï¼š`è¯è¯­ æƒé‡`ï¼ˆç”¨ç©ºæ ¼æˆ–åˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰
3. ç¤ºä¾‹ï¼š
   ```
   å¾ˆå¥½ 2.0
   éå¸¸æ£’ 2.5
   éš¾åƒ -2.0
   ```

### Q8: å¦‚ä½•ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†

**æ–¹æ³•ä¸€ï¼šä½¿ç”¨ç°æœ‰æ ¼å¼**
1. å‡†å¤‡æ•°æ®æ–‡ä»¶ï¼Œæ ¼å¼ä¸ `f_corpus/*.txt` ç›¸åŒ
2. æ¯è¡Œï¼š`pos/neg <tab> token1 <tab> token2 ...`
3. å‚è€ƒ `spa/corpus.py` åˆ›å»ºè‡ªå·±çš„ Corpus ç±»

**æ–¹æ³•äºŒï¼šç›´æ¥ä½¿ç”¨**
```python
from spa.classifiers import BayesClassifier
from spa.feature_extraction import ChiSquare

# å‡†å¤‡æ•°æ®
train_data = [["è¯1", "è¯2", "è¯3"], ["è¯4", "è¯5"]]  # åˆ†è¯åçš„åˆ—è¡¨
train_labels = [1, 0]  # 1=æ­£é¢ï¼Œ0=è´Ÿé¢

# ç‰¹å¾é€‰æ‹©
chi = ChiSquare(train_data, train_labels)
best_words = chi.best_words(1000)

# è®­ç»ƒ
classifier = BayesClassifier(train_data, train_labels, best_words)
```

## ğŸ“Š æ€§èƒ½å‚è€ƒ

### è¯å…¸æ–¹æ³•
- **å‡†ç¡®ç‡**ï¼š70-80%ï¼ˆå–å†³äºè¯å…¸è´¨é‡ï¼‰
- **é€Ÿåº¦**ï¼šéå¸¸å¿«ï¼ˆ< 0.1ç§’/å¥ï¼‰
- **æ— éœ€è®­ç»ƒ**

### æœºå™¨å­¦ä¹ æ–¹æ³•

**å¤–å–æ•°æ®é›†ï¼ˆ3000è®­ç»ƒ/1000æµ‹è¯•ï¼‰ï¼š**
- æœ´ç´ è´å¶æ–¯ï¼š~80-85%
- KNN (k=13)ï¼š~75-80%
- SVM (C=150)ï¼š~85-90%

**é…’åº—æ•°æ®é›†ï¼ˆ2200è®­ç»ƒ/800æµ‹è¯•ï¼‰ï¼š**
- æœ´ç´ è´å¶æ–¯ï¼š~85-88%
- SVMï¼š~88-92%

**ç”µå½±æ•°æ®é›†ï¼ˆè‹±æ–‡ï¼‰ï¼š**
- æœ´ç´ è´å¶æ–¯ï¼š~75-80%
- SVMï¼š~80-85%

## ğŸ¤ åˆ†äº«å’Œåä½œ

### åˆ†äº«ç»™ä»–äºº

**æ–¹å¼ä¸€ï¼šå‘é€æ•´ä¸ªé¡¹ç›®æ–‡ä»¶å¤¹**
1. å‹ç¼©é¡¹ç›®æ–‡ä»¶å¤¹
2. å‘é€ç»™å¯¹æ–¹
3. å¯¹æ–¹è§£å‹åè¿è¡Œ `pip install -r requirements.txt`
4. è¿è¡Œ `python app.py`

**æ–¹å¼äºŒï¼šä½¿ç”¨ Git**
```bash
# åˆå§‹åŒ–ä»“åº“
git init
git add .
git commit -m "Initial commit"

# æ¨é€åˆ° GitHub
git remote add origin https://github.com/yourusername/yourrepo.git
git push -u origin main

# å¯¹æ–¹å…‹éš†
git clone https://github.com/yourusername/yourrepo.git
```

**æ–¹å¼ä¸‰ï¼šéƒ¨ç½²åˆ°äº‘æœåŠ¡å™¨**
- ä½¿ç”¨ Herokuã€AWSã€é˜¿é‡Œäº‘ç­‰äº‘å¹³å°
- æä¾›å…¬ç½‘è®¿é—®åœ°å€

### åä½œå»ºè®®

**ä»£ç è´¡çŒ®ï¼š**
1. Fork é¡¹ç›®
2. åˆ›å»ºæ–°åˆ†æ”¯ï¼š`git checkout -b feature/your-feature`
3. æäº¤æ›´æ”¹ï¼š`git commit -m "Add your feature"`
4. æ¨é€åˆ†æ”¯ï¼š`git push origin feature/your-feature`
5. åˆ›å»º Pull Request

**æŠ¥å‘Šé—®é¢˜ï¼š**
- åœ¨ Issues ä¸­æè¿°é—®é¢˜
- æä¾›é”™è¯¯ä¿¡æ¯å’Œå¤ç°æ­¥éª¤
- é™„ä¸Šç³»ç»Ÿç¯å¢ƒä¿¡æ¯

## ğŸ“ License

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ‘¥ ä½œè€…

- é¡¹ç›®ç»´æŠ¤è€…ï¼š[æ‚¨çš„åå­—]
- è”ç³»æ–¹å¼ï¼š[æ‚¨çš„é‚®ç®±]

## ğŸ™ è‡´è°¢

- jieba ä¸­æ–‡åˆ†è¯ï¼šhttps://github.com/fxsjy/jieba
- scikit-learnï¼šhttps://scikit-learn.org/
- Flaskï¼šhttps://flask.palletsprojects.com/

## ğŸ“š å‚è€ƒæ–‡çŒ®

å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{sentiment_analysis_2025,
  author = {Your Name},
  title = {Sentiment Polarity Analysis System},
  year = {2025},
  url = {https://github.com/yourusername/SentimentPolarityAnalysis}
}
```

---

**æœ€åæ›´æ–°ï¼š2025å¹´11æœˆ12æ—¥**

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿æäº¤ Issue æˆ– Pull Requestï¼

## 1ã€é¢„å¤„ç†
### ï¼ˆ1ï¼‰ã€ç‰¹å¾æå–
- å¯¹åº”æ–‡ä»¶ï¼šfeature_extraction.py

æœ€åç»“æœï¼š

![chi1](files/pic/chi1.png)

X^2å€¼å‰å‡ åçš„è¯è¯­ã€‚èƒ½çœ‹å‡ºè¿™äº›è¯éƒ½æ˜¯ä¸€äº›æœ‰æ•ˆçš„æƒ…æ„Ÿè¯ã€‚â€œäº†â€è¿™æ ·çš„è¯å‡ºç°åœ¨å…¶ä¸­ï¼Œè¯´æ˜å¯ä»¥å»é™¤ä¸€äº›åœç”¨è¯ï¼Œæ¥è¿›ä¸€æ­¥æé«˜åˆ†ç±»ç²¾åº¦ã€‚

![chi2](files/pic/chi2.png)

X^2å€¼åå‡ åçš„è¯è¯­ã€‚èƒ½çœ‹å‡ºè¿™äº›è¯çš„åˆ†ç±»ä½œç”¨ä¸æ˜¯å¾ˆå¤§ã€‚

### ï¼ˆ2ï¼‰ã€ç»“æœè¯„ä»·
- å¯¹åº”æ–‡ä»¶ï¼štools.py

ç»“æœå±•ç¤º

![evaluation](files/pic/evaluation.PNG)

## 2ã€åŸºäºæƒ…æ„Ÿè¯å…¸çš„æƒ…æ„Ÿææ€§åˆ†æ 
â€”â€” sentiment analysis based on sentiment dict

- å¯¹åº”æ–‡ä»¶ï¼šclassifier.py  DictClassifier

### ä½¿ç”¨1ï¼šanalyse_sentence
analyse_sentence(sentence, runout_filepath=None, print_show=False)

å¯¹å•ä¸ªå¥å­è¿›è¡Œæƒ…æ„Ÿææ€§åˆ†æ

- sentenceï¼Œå¾…åˆ†æçš„å¥å­

- è‹¥runout_filepathæŒ‡å®šï¼Œåˆ™å°†åˆ†æç»“æœå†™å…¥è¯¥æ–‡ä»¶ï¼›

- è‹¥print_showä¸ºTrueï¼Œåˆ™åœ¨æ§åˆ¶å°è¾“å‡ºåˆ†æç»“æœã€‚

è¿è¡Œå®ä¾‹ï¼š
    
    d = DictClassifier()
    a_sentence = "å‰æ¤’é¸¡è›‹å¥½å’¸,åœŸè±†ä¸å¾ˆå¥½åƒ"
    result = ds.analyse_sentence(a_sentence)
    print(result)

### ä½¿ç”¨2:analysis_file
analysis_file(filepath_in, filepath_out, encoding="utf-8", print_show=False, start=0, end=-1)

- filepath_inï¼Œå¾…åˆ†æçš„å¥å­æ–‡ä»¶

- filepath_outï¼Œåˆ†æç»“æœè¾“å‡ºæ–‡ä»¶

- encodingï¼Œè¾“å…¥æ–‡ä»¶å­—ç¬¦ç¼–ç 

- print_showï¼Œæ˜¯å¦åœ¨æ§åˆ¶å°è¾“å‡º

- startï¼Œè¾“å…¥æ–‡ä»¶å¼€å§‹åˆ†æçš„å¥å­è¡Œæ•°

- endï¼Œè¾“å…¥æ–‡ä»¶ç»“æŸåˆ†æçš„å¥å­è¡Œæ•°

è¾“å‡ºå®ä¾‹ï¼š

    é€é¤å¿«ï¼Œæ€åº¦å¥½ï¼å‘³é“ä¸é”™ã€‚
    Score:6.0
    Sub-clause0: positive:å¿« 
    Sub-clause1: positive:å¥½ punctuation:ï¼ 
    Sub-clause2: positive:ä¸é”™ 
    
    è¿˜å¯ä»¥ï¼Œæ¯”é¢„è®¡æ—¶é—´æ™šäº†ä¸€å°æ—¶åˆ°ï¼Œä¸è¿‡è¿˜å¥½
    Score:-0.56
    Sub-clause0: positive:è¿˜å¯ä»¥ 
    Sub-clause1: negative:æ™šâ€¦â€¦å°æ—¶:æ™šäº†ä¸€å°æ—¶ å°æ—¶ 
    Sub-clause2: conjunction:ä¸è¿‡ positive:è¿˜å¥½


## 3ã€åŸºäºk-NNçš„æƒ…æ„Ÿææ€§åˆ†æ 
â€”â€” sentiment analysis based on k-NN

### single_k_classify(input_data)

ä½¿ç”¨å•ä¸ªkå€¼

    k = 3
    
    knn = KNNClassifier(train_data, train_labels, k=2, best_words=best_words)
    classify_labels = []

    print("KNNClassifiers is testing ...")
    for data in self.test_data:
        classify_labels.append(knn.classify(data))
    print("KNNClassifiers tests over.")

    filepath = "f_runout/KNN-train-%d-test-%d-k-%s-%s.xls" % \
               (train_num, test_num, k,
                datetime.datetime.now().strftime("%Y-%m-%d-%H-%M-%S"))

    results = get_accuracy(test_labels, classify_labels)
    Write2File.write_contents(filepath, results)

### multiple_k_classify(input_data)

ä½¿ç”¨å¤šä¸ªkå€¼

    from spa.classifiers import KNNClassifier
    
    k = [1, 3, 5, 7, 9, 11, 13]
    
    knn = KNNClassifier(train_data, train_labels, k=2, best_words=best_words)
    classify_labels = []

    print("KNNClassifiers is testing ...")
    for data in self.test_data:
        classify_labels.append(knn.classify(data))
    print("KNNClassifiers tests over.")

    filepath = "f_runout/KNN-train-%d-test-%d-k-%s-%s.xls" % \
               (train_num, test_num, '-'.join([str(i) for i in k]),
                datetime.datetime.now().strftime("%Y-%m-%d-%H-%M-%S"))

    results = get_accuracy(test_labels, classify_labels)
    Write2File.write_contents(filepath, results)

### æ¯”è¾ƒç»“è®º

åœ¨æŸäº›ç‰¹å®šæ•°æ®ä¸‹ï¼Œmultiple_kæ¯”æ¯ä¸ªsingle_kæ•ˆæœè¦å¥½ã€‚ä½†å¹¶ä¸æ˜¯æ€»æ˜¯æœ€å¥½ã€‚


## 4ã€åŸºäºBayesçš„æƒ…æ„Ÿææ€§åˆ†æ 
â€”â€” sentiment analysis based on bayes
    
    from spa.classifiers import BayesClassifier
    
    bayes = BayesClassifier(self.train_data, self.train_labels, self.best_words)

    classify_labels = []
    print("BayesClassifier is testing ...")
    for data in self.test_data:
        classify_labels.append(bayes.classify(data))
    print("BayesClassifier tests over.")

    filepath = "f_runout/bayes-train-%d-test-%d-k-%s-%s.xls" % \
               (train_num, test_num, '-'.join([str(i) for i in k]),
                datetime.datetime.now().strftime("%Y-%m-%d-%H-%M-%S"))

    results = get_accuracy(test_labels, classify_labels)
    Write2File.write_contents(filepath, results)


## 5ã€åŸºäºæœ€å¤§ç†µçš„æƒ…æ„Ÿææ€§åˆ†æ 
â€”â€” sentiment analysis based on maximum entropy

### ä½¿ç”¨1ï¼šå¾—åˆ°æ¯æ¬¡è¿­ä»£çš„å‡†ç¡®ç‡çš„å˜åŒ–

![maxent_iteration](files/pic/maxent_iteration.PNG)

    def test_maxent_iteration(self):
        print("MaxEntClassifier iteration")
        print("---" * 45)
        print("Train num = %s" % self.train_num)
        print("Test num = %s" % self.test_num)
        print("maxiter = %s" % self.max_iter)

        from spa.classifiers import MaxEntClassifier

        m = MaxEntClassifier(self.max_iter)
        iter_results = m.test(self.train_data, self.train_labels, self.best_words, self.test_data)

        filepath = "f_runout/MaxEnt-iteration-%s-train-%d-test-%d-f-%d-maxiter-%d-%s.xls" % \
                   (self.type,
                    self.train_num,
                    self.test_num,
                    self.feature_num,
                    self.max_iter,
                    datetime.datetime.now().strftime(
                        "%Y-%m-%d-%H-%M-%S"))

        results = []
        for i in range(len(iter_results)):
            try:
                results.append(get_accuracy(self.test_labels, iter_results[i], self.parameters))
            except ZeroDivisionError:
                print("ZeroDivisionError")

        Write2File.write_contents(filepath, results)

### ä½¿ç”¨2ï¼šå•ä¸ªå¥å­çš„æƒ…æ„Ÿææ€§åˆ’åˆ†

    def test_maxent(self):
        print("MaxEntClassifier")
        print("---" * 45)
        print("Train num = %s" % self.train_num)
        print("Test num = %s" % self.test_num)
        print("maxiter = %s" % self.max_iter)

        from spa.classifiers import MaxEntClassifier

        m = MaxEntClassifier(self.max_iter)
        m.train(self.train_data, self.train_labels, self.best_words)

        print("MaxEntClassifier is testing ...")
        classify_results = []
        for data in self.test_data:
            classify_results.append(m.classify(data))
        print("MaxEntClassifier tests over.")

        filepath = "f_runout/MaxEnt-%s-train-%d-test-%d-f-%d-maxiter-%d-%s.xls" % \
                   (self.type,
                    self.train_num, self.test_num,
                    self.feature_num, self.max_iter,
                    datetime.datetime.now().strftime(
                        "%Y-%m-%d-%H-%M-%S"))

        self.write(filepath, classify_results, 1)


## 6ã€åŸºäºSVMçš„æƒ…æ„Ÿææ€§åˆ†æ 
â€”â€” sentiment analysis based on SVM

ä¾èµ–äºscikit-learnåº“ã€‚å‡†ç¡®ç‡è¾ƒé«˜ï¼

    def test_svm(self):
        print("SVMClassifier")
        print("---" * 45)
        print("Train num = %s" % self.train_num)
        print("Test num = %s" % self.test_num)
        print("C = %s" % self.C)

        from spa.classifiers import SVMClassifier
        svm = SVMClassifier(self.train_data, self.train_labels, self.best_words, self.C)

        classify_labels = []
        print("SVMClassifier is testing ...")
        for data in self.test_data:
            classify_labels.append(svm.classify(data))
        print("SVMClassifier tests over.")

        filepath = "f_runout/SVM-%s-train-%d-test-%d-f-%d-C-%d-%s-lin.xls" % \
                   (self.type,
                    self.train_num, self.test_num,
                    self.feature_num, self.C,
                    datetime.datetime.now().strftime(
                        "%Y-%m-%d-%H-%M-%S"))

        self.write(filepath, classify_labels, 2)

## 7ã€å‡ ç§æƒ…æ„Ÿåˆ†ææ–¹æ³•æ¯”è¾ƒ

### åŸºäºè¯å…¸
- å‡†ç¡®ç‡ï¼šå‡†ç¡®ç‡è¾ƒé«˜ï¼ˆ80%ä»¥ä¸Šï¼‰ï¼Œéšç€äººå·¥å·¥ä½œé‡çš„å¢åŠ ï¼Œå‡†ç¡®ç‡å¢åŠ 

- ä¼˜ç‚¹ï¼šæ˜“äºç†è§£

- ç¼ºç‚¹ï¼šäººå·¥å·¥ä½œé‡å¤§

### åŸºäºk_NN
- å‡†ç¡®ç‡ï¼šå¾ˆä½ï¼ˆ60% - 70%ï¼‰

- ä¼˜ç‚¹ï¼šæ€æƒ³ç®€å•ã€ç®—æ³•ç®€å•

- ç¼ºç‚¹ï¼šå‡†ç¡®ç‡ä½ï¼›è€—å†…å­˜ï¼›è€—æ—¶é—´

### åŸºäºBayes
- å‡†ç¡®ç‡ï¼šè¿˜å¯ä»¥ï¼ˆ70% - 80%ï¼‰

- ä¼˜ç‚¹ï¼šç®€å•ï¼Œé«˜æ•ˆï¼Œè¿ç®—é€Ÿåº¦å¿«ï¼Œæ‰©å±•æ€§å¥½

- ç¼ºç‚¹ï¼šå‡†ç¡®ç‡ä¸é«˜ï¼Œè¾¾ä¸åˆ°å®ç”¨

### åŸºäºæœ€å¤§ç†µ
- å‡†ç¡®ç‡ï¼šæ¯”è¾ƒé«˜ï¼ˆ83%ä»¥ä¸Šï¼‰

- ä¼˜ç‚¹ï¼šå‡†ç¡®ç‡é«˜

- ç¼ºç‚¹ï¼šè®­ç»ƒæ—¶é—´ä¹…

### åŸºäºSVM
- å‡†ç¡®ç‡ï¼šæœ€é«˜ï¼ˆ85%ä»¥ä¸Šï¼‰

- ä¼˜ç‚¹ï¼šå‡†ç¡®ç‡é«˜

- ç¼ºç‚¹ï¼šè®­ç»ƒè€—æ—¶
